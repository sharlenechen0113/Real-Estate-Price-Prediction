{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model_resnet_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sharlenechen0113/Real-Estate-Price-Prediction/blob/main/model_resnet_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8WyP764oIcm"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLQUIvtkrJeb"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "import torchvision.models\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from sklearn import preprocessing, metrics, model_selection"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6DjvqmH_GLI"
      },
      "source": [
        "USE_GPU = True\n",
        "\n",
        "dtype = torch.float\n",
        "\n",
        "if USE_GPU and torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "# Constant to control how frequently we print train loss\n",
        "print_every = 100\n",
        "\n",
        "print('using device:', device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccHF8JGeenOE"
      },
      "source": [
        "train_mean = 0.0\n",
        "train_std = 0.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9wjEVcv-ck3"
      },
      "source": [
        "# load images\n",
        "from os import listdir, path\n",
        "\n",
        "images_list = listdir('/content/drive/MyDrive/SC201_Final_Project/images/map')\n",
        "\n",
        "print(images_list)\n",
        "\n",
        "image_dic_index = {}\n",
        "image_dic_latlng = {}\n",
        "for i in range(len(images_list)):\n",
        "  image_dic_index[i] = images_list[i][:len(images_list[i])-4]\n",
        "  image_dic_latlng[images_list[i][:len(images_list[i])-4]] = i\n",
        "print(image_dic_index)\n",
        "print(image_dic_latlng)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHfoZKWkMaIF"
      },
      "source": [
        "nan_cache = {}\n",
        "def data_preprocess(filename,mode='Train'):\n",
        "  data = pd.read_csv(filename)\n",
        "  data.insert(len(data.columns), 'index', '')\n",
        "  data.loc[data['lat_lng'] == '25_121.50227','lat_lng'] = '25.0_121.50227'\n",
        "  index_list = []\n",
        "  for index, row in data.iterrows():\n",
        "    index_list.append(image_dic_latlng[row[2]])\n",
        "  data['index'] = index_list\n",
        "  if mode == 'Train':\n",
        "    # split data to train, validation and test datsets\n",
        "    train_data, val_data = model_selection.train_test_split(data,test_size = 0.2)\n",
        "    means = train_data.mean()\n",
        "    train_data = train_data.fillna(means)\n",
        "    val_data = val_data.fillna(means)\n",
        "    for column in data:\n",
        "      nan_cache[column] = means\n",
        "    train_y = train_data.pop('price_30000')\n",
        "    val_y = val_data.pop('price_30000')\n",
        "    return train_data, val_data, train_y, val_y\n",
        "  elif mode == 'Test':\n",
        "    real_test_data = data.fillna(nan_cache)\n",
        "    return real_test_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtz_4XqiljNn"
      },
      "source": [
        "FILE = '/content/drive/MyDrive/SC201_Final_Project/Data/new_data_0902.csv' # Your File Path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSayswidD9Ks"
      },
      "source": [
        "train_data, val_data, train_y, val_y = data_preprocess(FILE,mode='Train')\n",
        "print(val_data.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gx26zfLSm5LM"
      },
      "source": [
        "train_mean = 154170.694\n",
        "train_std = 79570.40139\n",
        "to_drop = ['unit_price','price_15000','zoning', 'lat','lng','lat_lng','unit_berth_price','compartmented','management_committee','floors_area','establishment','clothing_store','home_goods_store','store','local_government_office','university','natural_feature','health','tourist_attraction','transit_station','food']\n",
        "for drop_items in to_drop:\n",
        "  train_data.pop(drop_items)\n",
        "  val_data.pop(drop_items)\n",
        "\n",
        "print(train_data.columns)\n",
        "print(val_data.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7Uv1R_F-r80"
      },
      "source": [
        "# load images to dictionary\n",
        "def load_imgs(lat_lng):\n",
        "  image = Image.open('/content/drive/MyDrive/SC201_Final_Project/images/map/{}.png'.format(lat_lng)).convert('RGB')\n",
        "  image = T.ToTensor()(image)\n",
        "  return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCONIJ4cf_S7"
      },
      "source": [
        "class HousingDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self,dataset,labels):\n",
        "    self.y_train = torch.tensor(labels.values,dtype=torch.float32).view(len(labels),1)\n",
        "    self.x_train = torch.tensor(dataset.values,dtype=torch.float32)\n",
        "    print(\"HousingDataset shape {}, {}\".format(self.x_train.shape, self.y_train.shape))\n",
        "  def __len__(self):\n",
        "    return len(self.y_train)\n",
        "  def __getitem__(self,idx):\n",
        "    index = int(self.x_train[idx][71])\n",
        "    # print(index)      # how to extract values from tensor\n",
        "    x_img = load_imgs(image_dic_index[index])\n",
        "    return self.x_train[idx], x_img , self.y_train[idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hM3Du4otxRXk"
      },
      "source": [
        "# Datasets load training examples one at a time, so we wrap each Dataset in a \n",
        "# DataLoader which iterates through the Dataset and forms minibatches. We divide\n",
        "# the training set into train and val sets by passing a Sampler object to the\n",
        "# DataLoader telling how it should sample from the underlying Dataset.\n",
        "# This is for after map data is loaded into the features, so shuffling is done\n",
        "BATCH_SIZE = 32\n",
        "def form_minibatch(data,mode='Train'):\n",
        "  if mode == 'Train':\n",
        "    data = DataLoader(data,batch_size=BATCH_SIZE,shuffle=True)\n",
        "  elif mode == 'Test':\n",
        "    data = DataLoader(data,batch_size=BATCH_SIZE)\n",
        "  return data\n",
        "\n",
        "train_dl = form_minibatch(HousingDataset(train_data,train_y))\n",
        "eval_dl = form_minibatch(HousingDataset(val_data,val_y),mode='Test')\n",
        "print(\"training size {}, eval size {}\".format(len(train_dl), len(eval_dl)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIyfT7CWtmLL"
      },
      "source": [
        "# model = MyModel()\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self,input_size,output_size):\n",
        "        super().__init__()\n",
        "        self.nn = nn.Sequential(\n",
        "        nn.Linear(input_size, 60),\n",
        "        nn.BatchNorm1d(60),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(60, 45),\n",
        "        nn.BatchNorm1d(45),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(45, output_size),\n",
        "        nn.BatchNorm1d(output_size),\n",
        "        )\n",
        "        # epoch 25-29\n",
        "        resnet = torchvision.models.resnet50(pretrained=True)\n",
        "        for param in resnet.parameters():\n",
        "          param.requires_grad = True\n",
        "        \n",
        "\n",
        "        self.features2 = nn.Sequential(\n",
        "              nn.AdaptiveAvgPool2d((224,224)),\n",
        "              *list(resnet.children())[:6],\n",
        "\n",
        "              # N x 512 * 28 * 28\n",
        "              nn.Conv2d(in_channels=512, out_channels=256, kernel_size=3, padding=1),\n",
        "              nn.BatchNorm2d(256),\n",
        "              nn.ReLU(),\n",
        "\n",
        "              # N x 256 * 28 * 28\n",
        "              nn.Conv2d(in_channels=256, out_channels=128, kernel_size=3, padding=1),\n",
        "              nn.BatchNorm2d(128),\n",
        "              nn.ReLU(),\n",
        "\n",
        "              # N x 128 * 28 * 28\n",
        "              nn.Conv2d(in_channels=128, out_channels=64, kernel_size=3, padding=1),\n",
        "              nn.BatchNorm2d(64),\n",
        "              nn.ReLU(),\n",
        "\n",
        "              # N x 64 x 28 x 28  \n",
        "              nn.Conv2d(in_channels=64, out_channels=32, kernel_size=3, padding=1),\n",
        "              nn.BatchNorm2d(32),\n",
        "              nn.ReLU(),\n",
        "\n",
        "              nn.MaxPool2d(kernel_size=2, stride=2),  \n",
        "\n",
        "              # N x 32 x 14 x 14\n",
        "              nn.Conv2d(in_channels=32, out_channels=16, kernel_size=3, padding=1),\n",
        "              nn.BatchNorm2d(16),\n",
        "              nn.ReLU(),\n",
        "\n",
        "              # N x 16 x 14 x 14\n",
        "              nn.Conv2d(in_channels=16, out_channels=8, kernel_size=3, padding=1),\n",
        "              nn.BatchNorm2d(8),\n",
        "              nn.ReLU(),\n",
        "\n",
        "              nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "              # N x 8 x 7 x 7\n",
        "              \n",
        "              nn.Flatten(),\n",
        "              nn.Linear(8*7*7,output_size)\n",
        "          )\n",
        "        self.metrics = 0\n",
        "        self.fc_out = nn.Sequential(\n",
        "            nn.Linear(output_size*2,output_size)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self,x1,x2):\n",
        "        x1 = self.nn(x1)\n",
        "        x1 = x1.view(x1.size(0), -1)\n",
        "        x1 = F.relu(x1)\n",
        "\n",
        "        x2 = self.features2(x2)\n",
        "        x2 = x2.view(x2.size(0), -1)\n",
        "        x2 = F.relu(x2)\n",
        "        # Concatenate in dim1 (feature dimension)\n",
        "        x = torch.cat((x1, x2),1)\n",
        "        scores = self.fc_out(x)\n",
        "        return scores\n",
        "\n",
        "net = MyModel(71,33)\n",
        "optimizer = torch.optim.Adam(net.parameters(),lr=1e-4,weight_decay=0.99)\n",
        "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=10)\n",
        "optimizer_SGD_momentum = torch.optim.SGD(net.parameters(),lr=1e-5,momentum=0.9,weight_decay=0.98)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dstr6LhxqYi7"
      },
      "source": [
        "loss_history=[]\n",
        "def train(data1, data2, model, optimizer, epochs=1):\n",
        "    \"\"\"\n",
        "    Train a model on real estate data property features \n",
        "    and extracte map features using the PyTorch Module API.\n",
        "    \n",
        "    Inputs:\n",
        "    - data1: training data\n",
        "    - data2: validation data\n",
        "    - model: A PyTorch Module giving the model to train.\n",
        "    - optimizer: An Optimizer object we will use to train the model\n",
        "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
        "    \n",
        "    Returns: Nothing, but prints model accuracies during training.\n",
        "    \"\"\"\n",
        "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
        "    for e in range(epochs):\n",
        "        for t, (x,x2,y) in enumerate(data1):\n",
        "            model.train()  # put model to training mode\n",
        "            indices = torch.tensor(range(0, 71))    # how to drop column from tensor\n",
        "            x1 = torch.index_select(x, 1, indices)\n",
        "            x1 = x1.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
        "            x2 = x2.to(device=device,dtype=dtype)\n",
        "            y = y.to(device=device, dtype=torch.long)\n",
        "            \n",
        "            # Zero out all of the gradients for the variables which the optimizer\n",
        "            # will update.\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            scores = model(x1,x2)\n",
        "            y = torch.squeeze(y)\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "            loss = criterion(scores,y)\n",
        "\n",
        "            # This is the backwards pass: compute the gradient of the loss with\n",
        "            # respect to each  parameter of the model.\n",
        "            loss.backward()\n",
        "\n",
        "            # Actually update the parameters of the model using the gradients\n",
        "            # computed by the backwards pass.\n",
        "            optimizer.step()\n",
        "            \n",
        "            if t % 100 == 0:\n",
        "                # running_loss = 0.0\n",
        "                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
        "                print('Checking accuracy on validation set')\n",
        "                num_correct, num_samples, acc = check_accuracy(data2, model)\n",
        "                print('Epoch %d, Got %d / %d correct (%.2f)' % (e,num_correct, num_samples, acc))\n",
        "        lr_scheduler.step(model.metrics)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9D14y1dsq18C"
      },
      "source": [
        "def check_accuracy(data, model):\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval()  # set model to evaluation mode\n",
        "    with torch.no_grad():\n",
        "      for x,x2,y in data:\n",
        "        indices = torch.tensor(range(0, 71))\n",
        "        x1 = torch.index_select(x, 1, indices)\n",
        "        x1 = x1.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
        "        x2 = x2.to(device=device,dtype=dtype)\n",
        "        y = y.to(device=device, dtype=torch.long)\n",
        "        scores = model(x1,x2)\n",
        "        y = torch.squeeze(y)\n",
        "        _, preds = scores.max(1)\n",
        "        num_correct += (preds == y).sum()\n",
        "        num_samples += preds.size(0)\n",
        "      acc = float(num_correct) / num_samples\n",
        "      return num_correct, num_samples, 100*acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1HviY5VJZEg"
      },
      "source": [
        "train(train_dl, eval_dl, net,optimizer,epochs=28)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGnBRR0pW4I4"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(range(len(loss_history)),loss_history)\n",
        "plt.xlabel('iteration')\n",
        "plt.ylabel('training loss')\n",
        "plt.title('Training Loss history')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}